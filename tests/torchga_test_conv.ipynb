{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/albertopepe/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "# Make tensorflow not take over the entire GPU memory\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Set memory growth behavior (manually or automatically managed by CUDA)\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        # Set the memory fraction (optional, defaults to 1.0 meaning use all available memory)\n",
    "        torch.cuda.set_per_process_memory_fraction(1.0, i)\n",
    "        \n",
    "        # Optionally, you can also clear unused memory (this is the closest thing to memory growth in PyTorch)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "from torchga.torchga import GeometricAlgebra\n",
    "from torchga.blades import BladeKind\n",
    "from torchga.layers import GeometricProductConv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4, 16])\n",
      "tensor([[[[  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.]],\n",
      "\n",
      "         [[  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.]],\n",
      "\n",
      "         [[  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.]],\n",
      "\n",
      "         [[  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.],\n",
      "          [  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.],\n",
      "          [  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.],\n",
      "          [  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.]]],\n",
      "\n",
      "\n",
      "        [[[  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.]],\n",
      "\n",
      "         [[  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.]],\n",
      "\n",
      "         [[  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.],\n",
      "          [  0., -36.,   0.,  36.,   0.,  36.,  36., -36.,  36.,   0.,  36.,\n",
      "            36.,  36.,  36.,  36.,  36.]],\n",
      "\n",
      "         [[  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.],\n",
      "          [  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.],\n",
      "          [  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.],\n",
      "          [  0., -24.,   0.,  24.,   0.,  24.,  24., -24.,  24.,   0.,  24.,\n",
      "            24.,  24.,  24.,  24.,  24.]]]])\n"
     ]
    }
   ],
   "source": [
    "ga = GeometricAlgebra([0, 1, 1, 1])\n",
    "\n",
    "batch_size = 2\n",
    "sequence_length = 8\n",
    "c_in = 3\n",
    "c_out = 4\n",
    "kernel_size = 3\n",
    "\n",
    "a = ga.from_tensor_with_kind(torch.ones([batch_size, sequence_length, c_in, ga.num_blades]), BladeKind.MV)\n",
    "k = ga.from_tensor_with_kind(torch.ones([kernel_size, c_in, c_out, ga.num_blades]), BladeKind.MV)\n",
    "\n",
    "y = ga.geom_conv1d(a, k, 2, \"SAME\")\n",
    "\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '12',\n",
       " '13',\n",
       " '23',\n",
       " '012',\n",
       " '013',\n",
       " '023',\n",
       " '123',\n",
       " '0123']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga.blades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 4, 16])\n",
      "MultiVector[batch_shape=torch.Size([2, 8, 4])]\n",
      "MultiVector[-0.49*1 + 0.94*e_0 + -0.55*e_1 + -0.18*e_2 + -0.97*e_3 + -0.44*e_01 + -0.98*e_02 + -0.58*e_03 + -0.08*e_12 + -0.05*e_13 + -0.00*e_23 + 0.49*e_012 + -0.23*e_013 + 0.62*e_023 + -0.09*e_123 + -0.71*e_0123]\n"
     ]
    }
   ],
   "source": [
    "mv_indices = torch.arange(0, ga.num_blades, dtype=torch.int64)\n",
    "\n",
    "conv_layer = GeometricProductConv1D(\n",
    "    ga, num_input_filters=c_in, num_output_filters=c_out, kernel_size=kernel_size, stride=1, padding=\"SAME\",\n",
    "    blade_indices_kernel=torch.arange(0, ga.num_blades, dtype=torch.int64),\n",
    "    blade_indices_bias=torch.arange(0, ga.num_blades, dtype=torch.int64)\n",
    ")\n",
    "\n",
    "y2 = conv_layer(a)\n",
    "print(y2.shape)\n",
    "ga.print(y2)\n",
    "ga.print(y2[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index_add_(): Number of indices (6) should be equal to source.size(dim): (16), for dim: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m c_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m      7\u001b[0m kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m---> 10\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mga\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_with_kind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mga\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_blades\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBladeKind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBIVECTOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/gpfs/home/a/albertopepe/linesregistration/torchga/torchga.py:294\u001b[0m, in \u001b[0;36mGeometricAlgebra.from_tensor_with_kind\u001b[0;34m(self, tensor, kind)\u001b[0m\n\u001b[1;32m    291\u001b[0m kind_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_kind_blade_indices(kind)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Call from_tensor (assuming this function works similarly in PyTorch)\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/home/a/albertopepe/linesregistration/torchga/torchga.py:271\u001b[0m, in \u001b[0;36mGeometricAlgebra.from_tensor\u001b[0;34m(self, tensor, blade_indices)\u001b[0m\n\u001b[1;32m    261\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto(tensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#print(output)\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m#print(tensor)\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m#print(blade_indices)\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m#print(tensor)\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblade_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m*\u001b[39mt_inv)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index_add_(): Number of indices (6) should be equal to source.size(dim): (16), for dim: 0"
     ]
    }
   ],
   "source": [
    "ga = GeometricAlgebra([1, 1, 1, 1])\n",
    "\n",
    "batch_size = 2\n",
    "sequence_length = 6\n",
    "c_in = 3\n",
    "c_out = 4\n",
    "kernel_size = 3\n",
    "\n",
    "\n",
    "a = ga.from_tensor_with_kind(torch.ones([batch_size, sequence_length, c_in, ga.num_blades]), BladeKind.BIVECTOR)\n",
    "print(a.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cliff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
