{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "import os\n",
    "from torchga.torchga import GeometricAlgebra\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.infer.mcmc as mcmc\n",
    "from pyro.infer.mcmc import HMC, MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/albertopepe/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Set memory growth behavior (manually or automatically managed by CUDA)\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        # Set the memory fraction (optional, defaults to 1.0 meaning use all available memory)\n",
    "        torch.cuda.set_per_process_memory_fraction(1.0, i)\n",
    "        \n",
    "        # Optionally, you can also clear unused memory (this is the closest thing to memory growth in PyTorch)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache() \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}', flush = True)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Electrodynamics with Geometric Algebra (WIP)\n",
    "\n",
    "## Theory overview\n",
    "Quantum Electrodynamics (QED) describes electrons, positrons (anti-electrons) and photons in a 4-dimensional spacetime with fields defined for all spacetime positions $X$. The 4-dimensional spacetime can be described by the [Spacetime Algebra (STA)](https://en.wikipedia.org/wiki/Spacetime_algebra) with basis vectors $\\gamma_0, \\gamma_1, \\gamma_2, \\gamma_3$ and corresponding metric $[1, -1, -1, -1]$. It contains two fields. The electron-positron field is a bispinor-field $\\psi(X)$ which in the context of Geometric Algebra (GA) is described by even-grade multivectors of the STA. The photon field $A(X)$ is a vector-field (ie. multivectors of degree 1, one basis for each dimension).\n",
    "\n",
    "A field configuration, also known as a path, $P(X)$ contains values for the two fields at every spacetime position. Our goal is to calculate the QED action using GA which allows us to use algorithms that solve for field configurations . The action is the negative log-likelihood (NLL) of the field configuration, meaning it is a number which tells how likely a given field configuration is. It is not a probability as it is unnormalized. However even with only the NLL we can use sampling algorithms (eg. [Markov-Chain Monte-Carlo](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo), [Variational Inference](https://en.wikipedia.org/wiki/Variational_Bayesian_methods)) to sample field configurations so that the sampled distribution matches the normalized distribution.\n",
    "\n",
    "The Lagrangian is given in Hestenes' article [Real Dirac Theory](https://www.researchgate.net/publication/266578033_REAL_DIRAC_THEORY) in equation (B.6) as\n",
    "\n",
    "$\\mathcal{L} = \\langle \\hbar (\\nabla \\psi(X)) i \\gamma_3 \\widetilde{\\psi}(X) - e A(X) \\psi(X) \\gamma_0 \\widetilde{\\psi}(X) - m \\psi(X) \\widetilde{\\psi}(X) \\rangle$\n",
    "\n",
    "where $\\langle ... \\rangle$ denotes getting the scalar part, $i = \\gamma_2 \\gamma_1$, $\\nabla = \\sum_{i=0}^{3} \\gamma_i \\delta^i$ and $\\widetilde{\\psi}(X)$ is the grade-reversal of $\\psi$.\n",
    "\n",
    "The action $S(P)$ for a field-configuration $P=(\\psi, A)$ is calculated by integrating the Lagrangian $\\mathcal{L}(P, X)$ over all space-time positions $X$.\n",
    "\n",
    "$S(\\psi, A) = \\int_{X \\in \\mathcal{X}} \\mathcal{L}(\\psi, A, X) dx$\n",
    "\n",
    "Finally as we are doing this numerically we need to discretize spacetime into a 4-dimensional grid. Integrals over spacetime then become sums over the grid. Derivatives become finite-differences or more complicated operations to avoid the [aliasing](https://arxiv.org/abs/hep-lat/0207008) which results in the [fermion doubling](https://en.wikipedia.org/wiki/Fermion_doubling) problem.\n",
    "\n",
    "## Getting started\n",
    "Let's start by defining the spacetime algebra as a geometric algebra in 1 time and 3 space dimensions with metric $[1, -1, -1, -1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiVector[1.00*e_0]\n",
      "MultiVector[1.00*e_1]\n",
      "MultiVector[1.00*e_2]\n",
      "MultiVector[1.00*e_3]\n"
     ]
    }
   ],
   "source": [
    "sta = GeometricAlgebra([1, -1, -1, -1])\n",
    "for basis in sta.basis_mvs:\n",
    "    sta.print(basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our four basis vectors displayed here each with a different ... basis. Let's try squaring them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_0^2: MultiVector[1.00*1]\n",
      "e_1^2: MultiVector[-1.00*1]\n",
      "e_2^2: MultiVector[-1.00*1]\n",
      "e_3^2: MultiVector[-1.00*1]\n"
     ]
    }
   ],
   "source": [
    "print(\"e_0^2:\", sta(sta.e0) ** 2)\n",
    "print(\"e_1^2:\", sta(sta.e1) ** 2)\n",
    "print(\"e_2^2:\", sta(sta.e2) ** 2)\n",
    "print(\"e_3^2:\", sta(sta.e3) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squaring the basis vectors gave us back another purely scalar multivector. The squared bases indeed return the correct metric.\n",
    "\n",
    "We can create new multivectors of different kinds using the geometric algebra `sta_ga` object. Let's create some vectors such as the elements of the photon field and perform some operations to get a feel for them. We can use the methods on `sta_ga`, most of which take a `batch_shape` that says how many elements you want (`[]` meaning just a single one) and a `kind` that describes which elements it will set (eg. `\"even\"`, `\"mv\"` (meaning all), `\"vector\"`, `\"scalar\"`, ...). Alternatively we can just build everything out of the basis vectors ourselves by adding and multiplying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: MultiVector[1.00*e_0 + 1.00*e_1 + 1.00*e_2 + 1.00*e_3]\n",
      "v2: MultiVector[1.00*e_0 + 1.00*e_1]\n",
      "v1 * v2 (Geometric product): MultiVector[-1.00*e_02 + -1.00*e_03 + -1.00*e_12 + -1.00*e_13]\n",
      "v1 | v2 (Inner product): MultiVector[]\n",
      "v1 ^ v2 (Exterior product): MultiVector[-1.00*e_02 + -1.00*e_03 + -1.00*e_12 + -1.00*e_13]\n",
      "v3 = v1 + v2: MultiVector[2.00*e_0 + 2.00*e_1 + 1.00*e_2 + 1.00*e_3]\n",
      "v1 | v3: MultiVector[-2.00*1]\n",
      "v1 ^ v3: MultiVector[-1.00*e_02 + -1.00*e_03 + -1.00*e_12 + -1.00*e_13]\n",
      "v4 = v1 * v2: MultiVector[2.00*e_0 + 2.00*e_1 + 1.00*e_2 + 1.00*e_3]\n",
      "v1^-1 * v4: MultiVector[1.00*e_0 + 1.00*e_1] should be MultiVector[1.00*e_0 + 1.00*e_1]\n"
     ]
    }
   ],
   "source": [
    "v1 = sta.from_tensor_with_kind(torch.ones(4), kind=\"vector\")\n",
    "sta.print(\"v1:\", v1)\n",
    "\n",
    "v2 = sta.basis_mvs[0] + sta.basis_mvs[1]\n",
    "sta.print(\"v2:\", v2)\n",
    "\n",
    "sta.print(\"v1 * v2 (Geometric product):\", sta.geom_prod(v1, v2))\n",
    "sta.print(\"v1 | v2 (Inner product):\", sta.inner_prod(v1, v2))\n",
    "sta.print(\"v1 ^ v2 (Exterior product):\", sta.ext_prod(v1, v2))\n",
    "\n",
    "v3 = v1 + v2\n",
    "sta.print(\"v3 = v1 + v2:\", v3)\n",
    "sta.print(\"v1 | v3:\", sta.inner_prod(v1, v3))\n",
    "sta.print(\"v1 ^ v3:\", sta.ext_prod(v1, v3))\n",
    "\n",
    "v4 = sta.geom_prod(v1, v2)\n",
    "sta.print(\"v4 = v1 * v2:\", v3)\n",
    "sta.print(\"v1^-1 * v4:\", sta.geom_prod(sta.inverse(v1), v4), \"should be\", v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the bispinors (elements of even degree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1: MultiVector[1.00*1 + 1.00*e_01 + 1.00*e_02 + 1.00*e_03 + 1.00*e_12 + 1.00*e_13 + 1.00*e_23 + 1.00*e_0123]\n",
      "b2: MultiVector[4.00*1 + 2.00*e_01]\n",
      "b1 | b2: MultiVector[6.00*1 + 6.00*e_01 + 4.00*e_02 + 4.00*e_03 + 4.00*e_12 + 4.00*e_13 + 6.00*e_23 + 4.00*e_0123]\n",
      "b1 ^ b2: MultiVector[4.00*1 + 6.00*e_01 + 4.00*e_02 + 4.00*e_03 + 4.00*e_12 + 4.00*e_13 + 4.00*e_23 + 6.00*e_0123]\n",
      "b3 = b1 * b2: MultiVector[6.00*1 + 6.00*e_01 + 6.00*e_02 + 6.00*e_03 + 6.00*e_12 + 6.00*e_13 + 6.00*e_23 + 6.00*e_0123]\n",
      "b3 * b2^-1: MultiVector[1.00*1 + 1.00*e_01 + 1.00*e_02 + 1.00*e_03 + 1.00*e_12 + 1.00*e_13 + 1.00*e_23 + 1.00*e_0123] should be MultiVector[1.00*1 + 1.00*e_01 + 1.00*e_02 + 1.00*e_03 + 1.00*e_12 + 1.00*e_13 + 1.00*e_23 + 1.00*e_0123]\n",
      "~b2 (Grade reversal): MultiVector[4.00*1 + -2.00*e_01]\n",
      "Scalar part of b2: MultiVector[4.00*1]\n",
      "e_01 part of b2: MultiVector[2.00*e_01]\n"
     ]
    }
   ],
   "source": [
    "b1 = sta.from_tensor_with_kind(torch.ones(8), kind=\"even\")\n",
    "sta.print(\"b1:\", b1)\n",
    "\n",
    "b2 = sta.from_scalar(4.0) + sta.geom_prod(sta.basis_mvs[0], sta.basis_mvs[1]) + sta.geom_prod(sta.basis_mvs[0], sta.basis_mvs[1])\n",
    "sta.print(\"b2:\", b2)\n",
    "\n",
    "sta.print(\"b1 | b2:\", sta.inner_prod(b1, b2))\n",
    "sta.print(\"b1 ^ b2:\", sta.ext_prod(b1, b2))\n",
    "\n",
    "b3 = sta.geom_prod(b1, b2)\n",
    "sta.print(\"b3 = b1 * b2:\", b3)\n",
    "sta.print(\"b3 * b2^-1:\", sta.geom_prod(b3, sta.inverse(b2)), \"should be\", b1)\n",
    "\n",
    "sta.print(\"~b2 (Grade reversal):\", sta.reversion(b2))\n",
    "sta.print(\"Scalar part of b2:\", sta.keep_blades_with_name(b2, \"\"))\n",
    "sta.print(\"e_01 part of b2:\", sta.keep_blades_with_name(b2, \"01\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we hopefully have some feel for how to operate with the geometric algebra numbers. So far we only worked with single numbers, but we can define a field (ie. a number for every grid point) by passing in a `batch_shape` that is the size of our grid. When printing the fields we won't see the actual numbers anymore, we will only see which blades are non-zero and the batch shape. However we can still access all of the numbers with the usual indexing rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A(X): MultiVector[batch_shape=torch.Size([10, 10, 10, 10])]\n",
      "A(t=0, x=5, y=3, z=9): MultiVector[1.00*e_0 + 1.00*e_1 + 1.00*e_2 + 1.00*e_3]\n",
      "A(t=0, z=[3,4,5]): MultiVector[batch_shape=torch.Size([10, 10, 3])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/a/albertopepe/linesregistration/torchga/torchga.py:500: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  blade_indices = torch.tensor(blade_indices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_0 part of A(X): torch.Size([10, 10, 10, 10])\n",
      "A(0, 0, 0, 0) * ~A(0, 0, 0, 0): MultiVector[-2.00*1]\n"
     ]
    }
   ],
   "source": [
    "a = sta.from_tensor_with_kind(torch.ones((10, 10, 10, 10, 4)), kind=\"vector\")\n",
    "sta.print(\"A(X):\", a)\n",
    "\n",
    "sta.print(\"A(t=0, x=5, y=3, z=9):\", a[0, 5, 3, 9])\n",
    "sta.print(\"A(t=0, z=[3,4,5]):\", a[0, :, :, 3:6])\n",
    "sta.print(\"e_0 part of A(X):\", sta.select_blades_with_name(a, \"0\").shape)\n",
    "sta.print(\"A(0, 0, 0, 0) * ~A(0, 0, 0, 0):\", sta.geom_prod(a, sta.reversion(a))[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you will probably believe me that we can do the same to create a bispinor field, so instead let's see how we can calculate derivatives.\n",
    "\n",
    "As mentioned in the beginning, derivatives become finite differences. To calculate finite differences we can take a copy of the field, shift it back by one in a dimension and subtract it. For instance of we were to calculate the derivative\n",
    "in the time direction we would shift the entire field by -1 along the time axis to get `A(X + TimeDirection * GridSpacing)` and subtract the actual field from this shifted field. All that is left then is to divide by the grid spacing.\n",
    "\n",
    "`d/dt A(X) = (A(X + TimeDirection * GridSpacing) - A(X)) / GridSpacing`\n",
    "\n",
    "To actually do the shifting we will use the `with_changes` method which allows copying of the multivector and overriding of its blade values so we will just shift the blade values themselves using [tf.roll](https://www.tensorflow.org/api_docs/python/tf/roll). A better abstraction that doesn't require using the internal blade values might be added later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def finite_differences(field, axis, spacing):\n",
    "    # Roll the field tensor along the specified axis by shifting -1 position\n",
    "    shifted_field = torch.roll(field, shifts=-1, dims=axis)\n",
    "    \n",
    "    # Compute the finite difference along the specified axis\n",
    "    return (shifted_field - field) / spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d/dt A(X) = (A(X + TimeDirection * GridSpacing) - A(X)) / GridSpacing: MultiVector[batch_shape=torch.Size([10, 10, 10, 10])]\n",
      "d/dt A(0, 0, 0, 0): MultiVector[]\n"
     ]
    }
   ],
   "source": [
    "deriv_t_a = finite_differences(a, axis=0, spacing=0.1)\n",
    "sta.print(\"d/dt A(X) = (A(X + TimeDirection * GridSpacing) - A(X)) / GridSpacing:\", deriv_t_a)\n",
    "sta.print(\"d/dt A(0, 0, 0, 0):\", deriv_t_a[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe expectedly, as our field is just a constant value everywhere, we are left with a field that is zero everywhere. Now we have a finite differences operation that will work on fields of any kind.\n",
    "\n",
    "Now we have all the tools we need to actually calculate the QED action given a field configuration. As a reminder, the QED Lagrangian is given by\n",
    "\n",
    "$\\mathcal{L} = \\langle \\hbar (\\nabla \\psi(X)) i \\gamma_3 \\widetilde{\\psi}(X) - e A(X) \\psi(X) \\gamma_0 \\widetilde{\\psi}(X) - m \\psi(X) \\widetilde{\\psi}(X) \\rangle$\n",
    "\n",
    "and the action $S(\\psi, A)$ is the spacetime integral (now sum) over it.\n",
    "\n",
    "Let's start with the mass term on the right $m \\psi(X) \\widetilde{\\psi}(X)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def get_mass_term(psi, electron_mass):\n",
    "    return electron_mass * sta.geom_prod(psi, sta.reversion(psi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi: MultiVector[batch_shape=torch.Size([10, 10, 10, 10])]\n",
      "Psi at (0, 0, 0, 0): MultiVector[2.00*1 + 1.00*e_01 + 1.00*e_02 + 1.00*e_03 + 1.00*e_12 + 1.00*e_13 + 1.00*e_23 + 1.00*e_0123]\n",
      "Mass term: MultiVector[batch_shape=torch.Size([10, 10, 10, 10])]\n",
      "Mass term at (0, 0, 0, 0): MultiVector[3.00*1 + 2.00*e_0123]\n"
     ]
    }
   ],
   "source": [
    "# Define psi as some arbitrary even-graded field for now\n",
    "psi = sta.from_tensor_with_kind(torch.ones([10, 10, 10, 10, 8]), kind=\"even\") + sta.from_tensor_with_kind(torch.ones([10, 10, 10, 10, 1]), kind=\"scalar\")\n",
    "sta.print(\"Psi:\", psi)\n",
    "sta.print(\"Psi at (0, 0, 0, 0):\", psi[0, 0, 0, 0])\n",
    "\n",
    "# The electron mass in planck units (hbar=1, c=1) is actually not 1 but something tiny.\n",
    "# However we won't bother with it for now.\n",
    "mass_term = get_mass_term(psi=psi, electron_mass=1.0)\n",
    "sta.print(\"Mass term:\", mass_term)\n",
    "sta.print(\"Mass term at (0, 0, 0, 0):\", mass_term[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the interaction term in the center that describes the scattering between the electron-positron field and the photon field $e A(X) \\psi(X) \\gamma_0 \\widetilde{\\psi}(X)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_term(psi, a, electron_charge):\n",
    "    return sta.geom_prod(electron_charge * a, sta.geom_prod(psi, sta.geom_prod(sta.e(\"0\"), sta.reversion(psi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction term: MultiVector[batch_shape=torch.Size([10, 10, 10, 10])]\n",
      "Interaction term at (0, 0, 0, 0): MultiVector[25.00*1 + -13.00*e_01 + -13.00*e_02 + -21.00*e_03 + -8.00*e_13 + -8.00*e_23]\n"
     ]
    }
   ],
   "source": [
    "interaction_term = get_interaction_term(psi=psi, a=a, electron_charge=1.0)\n",
    "sta.print(\"Interaction term:\", interaction_term)\n",
    "sta.print(\"Interaction term at (0, 0, 0, 0):\", interaction_term[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the momentum term for which we needed the finite differences $\\hbar (\\nabla \\psi(X)) i \\gamma_3 \\widetilde{\\psi}(X)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def get_momentum_term(psi, spacing, hbar):\n",
    "    # Nabla Psi\n",
    "    dt_psi = finite_differences(psi, axis=0, spacing=spacing)\n",
    "    dx_psi = finite_differences(psi, axis=1, spacing=spacing)\n",
    "    dy_psi = finite_differences(psi, axis=2, spacing=spacing)\n",
    "    dz_psi = finite_differences(psi, axis=3, spacing=spacing)\n",
    "    d_psi = dt_psi + dx_psi + dy_psi + dz_psi\n",
    "\n",
    "    return sta.geom_prod(hbar * d_psi, sta.geom_prod(sta.e(\"213\"), sta.reversion(psi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momentum term: MultiVector[batch_shape=torch.Size([10, 10, 10, 10])]\n",
      "Momentum term at (0, 0, 0, 0): MultiVector[]\n"
     ]
    }
   ],
   "source": [
    "momentum_term = get_momentum_term(psi=psi, spacing=0.1, hbar=1.0)\n",
    "\n",
    "sta.print(\"Momentum term:\", momentum_term)\n",
    "sta.print(\"Momentum term at (0, 0, 0, 0):\", momentum_term[0, 0, 0, 0]) # Still zero ;("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the terms, we can add them up, sum over all grid points and take the scalar part to get the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(psi, a, spacing, electron_mass, electron_charge, hbar):\n",
    "    mass_term = get_mass_term(psi=psi, electron_mass=electron_mass)\n",
    "    interaction_term = get_interaction_term(psi=psi, a=a, electron_charge=electron_charge)\n",
    "    momentum_term = get_momentum_term(psi=psi, spacing=spacing, hbar=hbar)\n",
    "\n",
    "    # Sum terms and get scalar part\n",
    "    lagrangians = (momentum_term - mass_term - interaction_term)[..., 0]\n",
    "\n",
    "    # Sum lagrangians (one lagrangian for each spacetime point) over spacetime\n",
    "    # to get a single value, the action.\n",
    "    return torch.sum(lagrangians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: tensor(-280000.)\n"
     ]
    }
   ],
   "source": [
    "action = get_action(psi=psi, a=a, spacing=0.1, electron_mass=1.0, electron_charge=1.0, hbar=1.0)\n",
    "print(\"Action:\", action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can calculate the action for a given field configuration (ie. values for `psi` and `a` at every grid point) we could use a sampling algorithm\n",
    "to sample fields and calculate quantities of interest such as the correlation function, vacuum energy and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must provide valid initial parameters to begin sampling when using `potential_fn` in HMC/NUTS kernel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m variable_step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m  \u001b[38;5;66;03m# Define step size\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Run sampling\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m psi_samples, a_samples \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_step_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Print the shapes of the samples for debugging\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPsi Samples shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpsi_samples\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m, in \u001b[0;36msample\u001b[0;34m(initial_state, step_size, num_chains)\u001b[0m\n\u001b[1;32m     21\u001b[0m hmc_kernel \u001b[38;5;241m=\u001b[39m HMC(potential_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m psi, a: \u001b[38;5;241m-\u001b[39mjoint_log_prob(psi, a),\n\u001b[1;32m     22\u001b[0m                  step_size\u001b[38;5;241m=\u001b[39mstep_size,\n\u001b[1;32m     23\u001b[0m                  num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# equivalent to num_leapfrog_steps\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Define the MCMC sampler with multiple chains and 300 samples\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m mcmc_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mMCMC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhmc_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_chains\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Ensure initial parameters are provided as a dictionary\u001b[39;00m\n\u001b[1;32m     29\u001b[0m initial_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsi\u001b[39m\u001b[38;5;124m\"\u001b[39m: initial_state[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;66;03m# Initial psi_config (bispinor field)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: initial_state[\u001b[38;5;241m1\u001b[39m]     \u001b[38;5;66;03m# Initial a_config (vector field)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m }\n",
      "File \u001b[0;32m~/.conda/envs/cliff/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:478\u001b[0m, in \u001b[0;36mMCMC.__init__\u001b[0;34m(self, kernel, num_samples, warmup_steps, initial_params, num_chains, hook_fn, mp_context, disable_progbar, disable_validation, transforms, save_params)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     kernel\u001b[38;5;241m.\u001b[39msave_params \u001b[38;5;241m=\u001b[39m save_params\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m parallel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_chains \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# check that initial_params is different for each chain\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cliff/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:391\u001b[0m, in \u001b[0;36mAbstractMCMC._validate_kernel\u001b[0;34m(self, initial_params)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, (HMC, NUTS))\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mpotential_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m ):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m initial_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide valid initial parameters to begin sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m when using `potential_fn` in HMC/NUTS kernel.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    394\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Must provide valid initial parameters to begin sampling when using `potential_fn` in HMC/NUTS kernel."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.infer.mcmc as mcmc\n",
    "from pyro.infer.mcmc import HMC, MCMC\n",
    "\n",
    "# Define the joint log probability function\n",
    "def joint_log_prob(psi_config, a_config):\n",
    "    # This function must take the parameters `psi_config` and `a_config` and return the log probability (negative action)\n",
    "    # Ensure that `get_action` and `sta.from_tensor_with_kind` work with PyTorch tensors.\n",
    "    mv_psi_config = sta.from_tensor_with_kind(psi_config, \"even\")\n",
    "    mv_a_config = sta.from_tensor_with_kind(a_config, \"vector\")\n",
    "\n",
    "    # Calculate the action (negative log likelihood)\n",
    "    action = get_action(mv_psi_config, mv_a_config, spacing=1e-7, electron_mass=1e-5,\n",
    "                        electron_charge=0.0854245, hbar=1.0)\n",
    "    return -action  # Return negative action as the log probability\n",
    "\n",
    "# Define the sampling function using Pyro's HMC and MCMC\n",
    "def sample(initial_state, step_size, num_chains=50):\n",
    "    # Define the HMC kernel using `potential_fn` (joint_log_prob in this case)\n",
    "    hmc_kernel = HMC(potential_fn=lambda psi, a: -joint_log_prob(psi, a),\n",
    "                     step_size=step_size,\n",
    "                     num_steps=3)  # equivalent to num_leapfrog_steps\n",
    "\n",
    "    # Define the MCMC sampler with multiple chains and 300 samples\n",
    "    mcmc_sampler = MCMC(hmc_kernel, num_samples=300, warmup_steps=1000, num_chains=num_chains)\n",
    "    \n",
    "    # Ensure initial parameters are provided as a dictionary\n",
    "    initial_params = {\n",
    "        \"psi\": initial_state[0],  # Initial psi_config (bispinor field)\n",
    "        \"a\": initial_state[1]     # Initial a_config (vector field)\n",
    "    }\n",
    "\n",
    "    # Debug: Check the initial parameter shapes to ensure they're correct\n",
    "    print(f\"Initial psi shape: {initial_params['psi'].shape}\")\n",
    "    print(f\"Initial a shape: {initial_params['a'].shape}\")\n",
    "\n",
    "    # Run the MCMC sampler with initial parameters\n",
    "    mcmc_sampler.run(initial_params)\n",
    "\n",
    "    # Extract samples from the MCMC sampler\n",
    "    samples = mcmc_sampler.get_samples()\n",
    "    psi_samples = samples['psi']\n",
    "    a_samples = samples['a']\n",
    "    \n",
    "    return psi_samples, a_samples\n",
    "\n",
    "# Example usage\n",
    "gs = 6  # grid size\n",
    "num_chains = 50\n",
    "\n",
    "# Initialize the state tensors for both `psi` and `a` fields (use zeros here for example)\n",
    "initial_state = [\n",
    "    torch.zeros((num_chains, gs, gs, gs, gs, 8)),  # Initial psi_config (bispinor field)\n",
    "    torch.zeros((num_chains, gs, gs, gs, gs, 4))   # Initial a_config (vector field)\n",
    "]\n",
    "\n",
    "variable_step_size = 0.001  # Define step size\n",
    "\n",
    "# Run sampling\n",
    "psi_samples, a_samples = sample(initial_state, variable_step_size, num_chains=num_chains)\n",
    "\n",
    "# Print the shapes of the samples for debugging\n",
    "print(f\"Psi Samples shape: {psi_samples.shape}\")\n",
    "print(f\"A Samples shape: {a_samples.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(chain_samples[0].shape)\n",
    "print(chain_samples[1].shape)\n",
    "print(torch.sum(torch.abs(chain_samples[0][0, 0] - chain_samples[0][1, 0])))\n",
    "print(torch.sum(torch.abs(chain_samples[0][1, 0] - chain_samples[0][2, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(5, 5))\n",
    "for i in range(4):\n",
    "    ax = axes[i % 2][i // 2]\n",
    "    im = ax.imshow(chain_samples[1][0, 0, 0, 0, :, :, i])\n",
    "    fig.colorbar(im, ax=ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(10, 5))\n",
    "for i in range(8):\n",
    "    ax = axes[i % 2][i // 2]\n",
    "    im = ax.imshow(chain_samples[0][0, 0, 0, 0, :, :, i])\n",
    "    fig.colorbar(im, ax=ax)\n",
    "fig.show()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(10, 5))\n",
    "for i in range(8):\n",
    "    ax = axes[i % 2][i // 2]\n",
    "    im = ax.imshow(chain_samples[0][0, 0, 0, 1, :, :, i])\n",
    "    fig.colorbar(im, ax=ax)\n",
    "fig.show()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(10, 5))\n",
    "for i in range(8):\n",
    "    ax = axes[i % 2][i // 2]\n",
    "    im = ax.imshow(chain_samples[0][0, 0, 0, 2, :, :, i])\n",
    "    fig.colorbar(im, ax=ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(10, 5))\n",
    "for i in range(8):\n",
    "    ax = axes[i % 2][i // 2]\n",
    "    im = ax.imshow(chain_samples[0][0, 0, 0, 0, :, :, i])\n",
    "    fig.colorbar(im, ax=ax)\n",
    "fig.show()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(10, 5))\n",
    "for i in range(8):\n",
    "    ax = axes[i % 2][i // 2]\n",
    "    im = ax.imshow(chain_samples[0][100, 0, 0, 0, :, :, i])\n",
    "    fig.colorbar(im, ax=ax)\n",
    "fig.show()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(10, 5))\n",
    "for i in range(8):\n",
    "    ax = axes[i % 2][i // 2]\n",
    "    im = ax.imshow(chain_samples[0][200, 0, 0, 0, :, :, i])\n",
    "    fig.colorbar(im, ax=ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"bmh\"):\n",
    "    def plot_correlations(ax, samples, axis):\n",
    "        correlation_by_shift = []\n",
    "        correlation_std_by_shift = []\n",
    "        shifts = list(range(1, samples.shape[axis]))\n",
    "\n",
    "        #if samples.shape[-1] == 8:\n",
    "        #    samples = sta.from_tensor_with_kind(samples, \"even\")\n",
    "        #elif samples.shape[-1] == 4:\n",
    "        #    samples = sta.from_tensor_with_kind(samples, \"vector\")\n",
    "\n",
    "        for i in shifts:\n",
    "            shifted = torch.roll(samples, shift=-i, dims=axis)\n",
    "            correlations = torch.mean(samples * shifted, axis=[-1, -2, -3, -4, -5])\n",
    "            #correlations = tf.reduce_mean(sta.inner_prod(samples, shifted), axis=[-1, -2, -3, -4, -5])\n",
    "            correlation_by_shift.append(torch.mean(correlations))\n",
    "            correlation_std_by_shift.append(torch.std(correlations))\n",
    "        ax.errorbar(shifts, correlation_by_shift, correlation_std_by_shift, capsize=5)\n",
    "\n",
    "    fig, axes = plt.subplots(4, sharex=True, sharey=True, figsize=(14, 8))\n",
    "    plot_correlations(axes[0], chain_samples[0], axis=-2)\n",
    "    plot_correlations(axes[1], chain_samples[0], axis=-3)\n",
    "    plot_correlations(axes[2], chain_samples[0], axis=-4)\n",
    "    plot_correlations(axes[3], chain_samples[0], axis=-5)\n",
    "\n",
    "    fig, axes = plt.subplots(4, sharex=True, sharey=True, figsize=(14, 8))\n",
    "    plot_correlations(axes[0], chain_samples[1], axis=-2)\n",
    "    plot_correlations(axes[1], chain_samples[1], axis=-3)\n",
    "    plot_correlations(axes[2], chain_samples[1], axis=-4)\n",
    "    plot_correlations(axes[3], chain_samples[1], axis=-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cliff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
